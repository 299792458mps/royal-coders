{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNn6LoHuBrVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx PyPDF2 pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcHaG2QYCGft",
        "outputId": "36096056-33a9-40b8-c0c5-c943e7212cb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLqVJFO3Egdf",
        "outputId": "24682fd8-83ab-45c1-8029-f57dcef7f6be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBvQhDeG9RG",
        "outputId": "552f51ee-6e48-438f-8d0b-11fb794f3453"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "import openpyxl\n",
        "import PyPDF2\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from io import BytesIO\n",
        "\n",
        "# --- Updated extraction functions ---\n",
        "\n",
        "def extract_text_from_docx(file_obj):\n",
        "    doc = Document(file_obj)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "\n",
        "def extract_text_from_excel(file_obj):\n",
        "    wb = openpyxl.load_workbook(file_obj, data_only=True)\n",
        "    text = \"\"\n",
        "    for sheet in wb:\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            row_text = [str(cell) if cell is not None else \"\" for cell in row]\n",
        "            text += \"\\t\".join(row_text) + \"\\n\"\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(file_obj):\n",
        "    text = \"\"\n",
        "    reader = PyPDF2.PdfReader(file_obj)\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or ''\n",
        "    return text\n",
        "\n",
        "\n",
        "def extract_text_from_image(file_obj):\n",
        "    image = Image.open(file_obj)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "\n",
        "# --- Main wrapper function ---\n",
        "\n",
        "def report_to_text(file_obj, filename):\n",
        "    ext = os.path.splitext(filename)[-1].lower()\n",
        "\n",
        "    if ext == \".docx\":\n",
        "        return extract_text_from_docx(file_obj)\n",
        "    elif ext in [\".xlsx\", \".xls\"]:\n",
        "        return extract_text_from_excel(file_obj)\n",
        "    elif ext == \".pdf\":\n",
        "        return extract_text_from_pdf(file_obj)\n",
        "    elif ext in [\".png\", \".jpg\", \".jpeg\"]:\n",
        "        return extract_text_from_image(file_obj)\n",
        "    else:\n",
        "        return \"Unsupported file format.\"\n",
        "\n",
        "\n",
        "# report_to_text(file_obj, filename)\n",
        "# --- Example usage for Colab or web upload ---\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     from google.colab import files  # Remove this if running outside Colab\n",
        "\n",
        "#     uploaded = files.upload()  # Upload one file\n",
        "#     for filename, file_data in uploaded.items():\n",
        "#         with BytesIO(file_data) as file_obj:\n",
        "#             text = report_to_text(file_obj, filename)\n",
        "#             print(\"Extracted Text:\\n\", text)\n"
      ],
      "metadata": {
        "id": "Z7ZcaaftBsKC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ZugwO18L-vro",
        "outputId": "882360f3-7265-4194-b5d7-10b8f30f8db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello world, this world is beautiful and amzaing , my friends are great. Hello world, \\xa0this world is\\xa0beautiful\\xa0and\\xa0amzaing \\xa0my\\xa0friends are great,Hello world\\xa0this\\xa0world is beautiful\\xa0and amzaed , my\\xa0friends\\xa0are great.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# apt-get install git\n",
        "\n",
        "# Clone the repository\n",
        "# git clone https://huggingface.co/deepset/xlm-roberta-large-squad2\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "use_local_model = False\n",
        "# If using a remote model (e.g., on the Hugging Face Hub), specify the exact model ID\n",
        "REMOTE_MODEL_ID = \"deepset/roberta-large-squad2\"\n",
        "\n",
        "# Chunking and Summarization\n",
        "def summarize_text_across_chunks(text, summarizer, chunk_size=700, overlap=100):\n",
        "    tokens = text.split()\n",
        "    summaries = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(tokens):\n",
        "        end = min(start + chunk_size, len(tokens))\n",
        "        chunk = \" \".join(tokens[start:end])\n",
        "        try:\n",
        "            summary = summarizer(chunk, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
        "            summaries.append(summary.strip())\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] Summarization failed on chunk: {e}\")\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "    # Optionally join all chunk summaries into a final summary\n",
        "    if len(summaries) == 1:\n",
        "        return summaries[0]\n",
        "    else:\n",
        "        final_summary = summarizer(\" \".join(summaries), max_length=100, min_length=50, do_sample=False)[0]['summary_text']\n",
        "        return final_summary\n",
        "\n",
        "# Load Summarization Pipeline\n",
        "def get_summarizer(use_local=False, model_id=\"facebook/bart-large-cnn\"):\n",
        "    \"\"\"\n",
        "    Loads a summarization model pipeline.\n",
        "    \"\"\"\n",
        "    if use_local:\n",
        "        print(\"[INFO] Local model loading is not supported here.\")\n",
        "        return None\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    summarizer = pipeline(\n",
        "        \"summarization\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1\n",
        "    )\n",
        "    return summarizer\n",
        "\n",
        "# Extract Summary from Text\n",
        "def extract_text_summary(text, summarizer):\n",
        "    return summarize_text_across_chunks(text, summarizer)\n",
        "\n",
        "def intialize_rag_model():\n",
        "  ragModel = get_summarizer(use_local_model)\n",
        "  return ragModel\n",
        "\n",
        "text = \"Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great,Hello world, this world is beautiful and amzaing , my friends are great\"\n",
        "# extract_text_summary(text, ragModel)\n",
        "\n",
        "ragModel = get_summarizer(use_local_model)\n",
        "extract_text_summary(text, ragModel)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3sEf-7Cn2P",
        "outputId": "20a5da6f-4aeb-49eb-94d8-f8eb8d1aad59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.0)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "# from a import report_to_text\n",
        "# from robertaModel import extract_text_summary, intialize_rag_model\n",
        "\n",
        "# Placeholder for document summarization\n",
        "def summarize_document(file, file_name):\n",
        "    text = report_to_text(file, file_name)\n",
        "    return extract_text_summary(text, ragModel)\n",
        "    # return text\n",
        "\n",
        "# Placeholder for processing voice input\n",
        "def process_voice_input(transcribed_text):\n",
        "    return f\"Processed response to: {transcribed_text}\"\n",
        "\n",
        "# Handle file upload and enable voice chat\n",
        "def handle_file_upload(file):\n",
        "    file_name = os.path.basename(file.name) if hasattr(file, \"name\") else str(file)\n",
        "    print(\"Uploaded file name:\", file_name)\n",
        "    summary = summarize_document(file, file_name)\n",
        "    return summary, gr.update(interactive=True)\n",
        "\n",
        "# Handle voice input and convert to text\n",
        "def handle_audio_input(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            print(f\"Recognized text: {text}\")\n",
        "            response = process_voice_input(text)\n",
        "            return response\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Sorry, could not understand the audio.\"\n",
        "        except sr.RequestError:\n",
        "            return \"Speech recognition service is unavailable.\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 📄 Voice Reports\n",
        "        **Upload a document to get a summary and enable voice chat!**\n",
        "        <br>\n",
        "        <span style='color:gray'>Step 1: Upload your document.<br>\n",
        "        Step 2: Review the summary.<br>\n",
        "        Step 3: Use your microphone to ask questions about the document.</span>\n",
        "        \"\"\",\n",
        "        elem_id=\"main-title\"\n",
        "    )\n",
        "\n",
        "    with gr.Accordion(\"📤 Document Upload & Summary\", open=True):\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Upload Document\")\n",
        "            summary_output = gr.Textbox(label=\"Summary\", lines=10, interactive=False, show_copy_button=True)\n",
        "\n",
        "    with gr.Accordion(\"🎤 Voice Chat\", open=True):\n",
        "        with gr.Row():\n",
        "            mic_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak Now\", interactive=False)\n",
        "            chat_output = gr.Textbox(label=\"Response\", lines=4, interactive=False, show_copy_button=True)\n",
        "\n",
        "    file_input.upload(fn=handle_file_upload, inputs=file_input, outputs=[summary_output, mic_input])\n",
        "    mic_input.change(fn=handle_audio_input, inputs=mic_input, outputs=chat_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "IFLY-1Ao-xNC",
        "outputId": "7287fd6b-5bb4-4c7b-842e-0848ff241e9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://562ce5a4855d3d8df6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://562ce5a4855d3d8df6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "text_file = \"\"\n",
        "\n",
        "def summarize_document(file):\n",
        "    file_name = os.path.basename(file.name) if hasattr(file, \"name\") else str(file)\n",
        "    text_file = report_to_text(file, file_name)\n",
        "    return extract_text_summary(text_file, ragModel)\n",
        "\n",
        "def summary_text_to_speech(summary_text):\n",
        "    if not summary_text or summary_text.strip() == \"\":\n",
        "        return None\n",
        "    tts = gTTS(text=summary_text, lang='en')\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
        "        tts.save(fp.name)\n",
        "        print(fp.name)\n",
        "        return fp.name\n",
        "\n",
        "# def summary_text_to_speech(summary_text):\n",
        "#     if not summary_text or summary_text.strip() == \"\":\n",
        "#         return None\n",
        "#     tts = gTTS(text=summary_text, lang='en')\n",
        "#     audio_path = \"summary_tts.mp3\"\n",
        "#     tts.save(audio_path)\n",
        "#     return \"/content/summary_tts.mp3\"\n",
        "\n",
        "def handle_file_upload(file, file_count):\n",
        "    file_name = os.path.basename(file.name) if hasattr(file, \"name\") else str(file)\n",
        "    print(\"Uploaded file name:\", file_name)\n",
        "    summary = summarize_document(file)\n",
        "    file_count += 1  # Increment count\n",
        "    summary_audio = summary_text_to_speech(summary)\n",
        "    # Enable voice chat after upload\n",
        "    return (\n",
        "        summary,\n",
        "        gr.update(value=None, interactive=True),\n",
        "        f\"Files uploaded this session: {file_count}\",\n",
        "        file_count,\n",
        "        summary_audio,\n",
        "        gr.update(interactive=True),  # Enable mic_input\n",
        "    )\n",
        "\n",
        "def process_voice_input(transcribed_text):\n",
        "    # Simulate sending the user's question to the AI backend and getting a response.\n",
        "    # Replace this with your actual AI backend call.\n",
        "    # ai_response = f\"{transcribed_text}\"\n",
        "    # return ai_response\n",
        "    # transcribed_text\n",
        "    return extract_text_summary( text_file, ragModel)\n",
        "\n",
        "def tts_response(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    audio_path = \"ai_response.mp3\"\n",
        "    tts.save(audio_path)\n",
        "    return audio_path\n",
        "\n",
        "def transcribe_audio(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            user_text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
        "            return user_text\n",
        "        except sr.UnknownValueError:\n",
        "            return \"[Unrecognized speech]\"\n",
        "        except sr.RequestError:\n",
        "            return \"[Speech recognition service unavailable]\"\n",
        "\n",
        "def handle_voice_chat(audio_file, chat_history):\n",
        "    if audio_file is None:\n",
        "        return chat_history, None, \"\\n\".join([f\"You: {u}\\nAI: {a}\" for u, a in zip(chat_history[::2], chat_history[1::2])]) if chat_history else \"\"\n",
        "    user_text = transcribe_audio(audio_file)\n",
        "    chat_history = chat_history or []\n",
        "    chat_history.append(f\"You: {user_text}\")\n",
        "    ai_text = process_voice_input(user_text)\n",
        "    chat_history.append(f\"AI: {ai_text}\")\n",
        "    ai_audio = tts_response(ai_text)\n",
        "    conversation_display = \"\\n\\n\".join(chat_history)\n",
        "    return chat_history, ai_audio, conversation_display\n",
        "\n",
        "def export_conversation(chat_history):\n",
        "    if not chat_history:\n",
        "        return None\n",
        "    conversation_text = \"\\n\\n\".join(chat_history)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(conversation_text)\n",
        "        return f.name\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 📄 Voice Reports\n",
        "        **Upload a document to get a summary and enable voice chat!**\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # --- File Upload & Summary Block ---\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 📤 Document Upload & Summary\")\n",
        "        file_count_state = gr.State(0)\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(\n",
        "                label=\"Upload Document\",\n",
        "                interactive=True\n",
        "            )\n",
        "            summary_output = gr.Textbox(label=\"Summary\", lines=10, interactive=False, show_copy_button=True)\n",
        "        file_count_display = gr.Markdown(\"Files uploaded this session: 0\")\n",
        "        gr.Markdown(\"**Tip:** Uploading a new file will automatically replace the previous one.\")\n",
        "        with gr.Row():\n",
        "            tts_audio = gr.Audio(label=\"Summary Audio\", interactive=True, autoplay=True)\n",
        "\n",
        "        file_input.upload(\n",
        "            fn=handle_file_upload,\n",
        "            inputs=[file_input, file_count_state],\n",
        "            outputs=[\n",
        "                summary_output,\n",
        "                file_input,\n",
        "                file_count_display,\n",
        "                file_count_state,\n",
        "                tts_audio,\n",
        "                # mic_input will be enabled after upload\n",
        "                # send_btn removed\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # --- Voice Chat Block ---\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 🎤 Voice Chat\")\n",
        "        conversation_state = gr.State([])\n",
        "        with gr.Row():\n",
        "            mic_input = gr.Audio(\n",
        "                sources=[\"microphone\"],\n",
        "                type=\"filepath\",\n",
        "                label=\"Speak Now\",\n",
        "                interactive=False  # Disabled until file upload\n",
        "            )\n",
        "            ai_audio = gr.Audio(label=\"AI Speaking\", interactive=False, autoplay=True)\n",
        "        chat_output = gr.Textbox(label=\"Conversation\", lines=12, interactive=False, show_copy_button=True)\n",
        "        with gr.Row():\n",
        "            export_btn = gr.Button(\"Export Conversation\")\n",
        "            export_file = gr.File(label=\"Download Conversation\")\n",
        "\n",
        "        # Automatically process voice when recording stops\n",
        "        mic_input.change(\n",
        "            fn=handle_voice_chat,\n",
        "            inputs=[mic_input, conversation_state],\n",
        "            outputs=[conversation_state, ai_audio, chat_output]\n",
        "        )\n",
        "\n",
        "        export_btn.click(\n",
        "            fn=export_conversation,\n",
        "            inputs=[conversation_state],\n",
        "            outputs=[export_file]\n",
        "        )\n",
        "\n",
        "    # Enable mic_input after file upload\n",
        "    file_input.upload(\n",
        "        fn=handle_file_upload,\n",
        "        inputs=[file_input, file_count_state],\n",
        "        outputs=[\n",
        "            summary_output,\n",
        "            file_input,\n",
        "            file_count_display,\n",
        "            file_count_state,\n",
        "            tts_audio,\n",
        "            mic_input  # Enable mic_input after upload\n",
        "        ]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "wOLqri6rFRXO",
        "outputId": "4a9ea1c0-c65c-46f9-b645-484494b99304"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2fe74ffb6f182ada0a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2fe74ffb6f182ada0a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import uuid\n",
        "import os\n",
        "import edge_tts\n",
        "import asyncio\n",
        "import io\n",
        "\n",
        "# ------------------------------\n",
        "# Placeholder summarization logic\n",
        "# ------------------------------\n",
        "def summarize_document(file):\n",
        "    return \"This is a placeholder summary. Replace this with actual summary logic.\"\n",
        "\n",
        "# ------------------------------\n",
        "# Save TTS to /content for Colab compatibility\n",
        "# ------------------------------\n",
        "async def text_to_speech_bytes(text):\n",
        "    communicate = edge_tts.Communicate(text, \"en-US-AriaNeural\")\n",
        "    stream = io.BytesIO()\n",
        "    async for chunk in communicate.stream():\n",
        "        if chunk[\"type\"] == \"audio\":\n",
        "            stream.write(chunk[\"data\"])\n",
        "    stream.seek(0)\n",
        "    return stream.read()\n",
        "\n",
        "def tts_response(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    file_path = f\"/content/ai_response_{uuid.uuid4().hex}.mp3\"\n",
        "    tts.save(file_path)\n",
        "    return file_path\n",
        "\n",
        "# ------------------------------\n",
        "# File upload handling\n",
        "# ------------------------------\n",
        "def handle_file_upload(file, file_count):\n",
        "    file_name = os.path.basename(file.name) if hasattr(file, \"name\") else str(file)\n",
        "    print(\"Uploaded file name:\", file_name)\n",
        "    summary = summarize_document(file)\n",
        "    file_count += 1\n",
        "    summary_audio = summary_text_to_speech(summary)\n",
        "    return (\n",
        "        summary,\n",
        "        gr.update(value=None, interactive=True),\n",
        "        f\"Files uploaded this session: {file_count}\",\n",
        "        file_count,\n",
        "        summary_audio,\n",
        "        gr.update(interactive=True)\n",
        "    )\n",
        "\n",
        "# ------------------------------\n",
        "# Voice chat processing\n",
        "# ------------------------------\n",
        "def transcribe_audio(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            user_text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
        "            return user_text\n",
        "        except sr.UnknownValueError:\n",
        "            return \"[Unrecognized speech]\"\n",
        "        except sr.RequestError:\n",
        "            return \"[Speech recognition service unavailable]\"\n",
        "\n",
        "def process_voice_input(transcribed_text):\n",
        "    # Simulated AI response\n",
        "    return f\"{transcribed_text}\"\n",
        "\n",
        "def handle_voice_chat(audio_file, chat_history):\n",
        "    if audio_file is None:\n",
        "        return chat_history, None, \"\\n\\n\".join(chat_history) if chat_history else \"\"\n",
        "    user_text = transcribe_audio(audio_file)\n",
        "    chat_history = chat_history or []\n",
        "    chat_history.append(f\"You: {user_text}\")\n",
        "    ai_text = process_voice_input(user_text)\n",
        "    chat_history.append(f\"AI: {ai_text}\")\n",
        "    ai_audio = tts_response(ai_text)\n",
        "    conversation_display = \"\\n\\n\".join(chat_history)\n",
        "    return chat_history, ai_audio, conversation_display\n",
        "\n",
        "# ------------------------------\n",
        "# Export chat to /content for download\n",
        "# ------------------------------\n",
        "def export_conversation(chat_history):\n",
        "    if not chat_history:\n",
        "        return None\n",
        "    conversation_text = \"\\n\\n\".join(chat_history)\n",
        "    file_path = f\"/content/conversation_{uuid.uuid4().hex}.txt\"\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(conversation_text)\n",
        "    return file_path\n",
        "\n",
        "# ------------------------------\n",
        "# Gradio UI\n",
        "# ------------------------------\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 📄 Voice Reports\n",
        "        **Upload a document to get a summary and enable voice chat!**\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # File upload section\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 📤 Document Upload & Summary\")\n",
        "        file_count_state = gr.State(0)\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Upload Document\", interactive=True)\n",
        "            summary_output = gr.Textbox(label=\"Summary\", lines=10, interactive=False, show_copy_button=True)\n",
        "        file_count_display = gr.Markdown(\"Files uploaded this session: 0\")\n",
        "        gr.Markdown(\"**Tip:** Uploading a new file will automatically replace the previous one.\")\n",
        "        with gr.Row():\n",
        "            tts_audio = gr.Audio(label=\"Summary Audio\", interactive=False, autoplay=True)\n",
        "\n",
        "        file_input.upload(\n",
        "            fn=handle_file_upload,\n",
        "            inputs=[file_input, file_count_state],\n",
        "            outputs=[\n",
        "                summary_output,\n",
        "                file_input,\n",
        "                file_count_display,\n",
        "                file_count_state,\n",
        "                tts_audio,\n",
        "                # mic_input will be enabled after upload\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Voice chat section\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 🎤 Voice Chat\")\n",
        "        conversation_state = gr.State([])\n",
        "        with gr.Row():\n",
        "            mic_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak Now\", interactive=False)\n",
        "            ai_audio = gr.Audio(label=\"AI Speaking\", interactive=False, autoplay=True)\n",
        "        chat_output = gr.Textbox(label=\"Conversation\", lines=12, interactive=False, show_copy_button=True)\n",
        "        with gr.Row():\n",
        "            export_btn = gr.Button(\"Export Conversation\")\n",
        "            export_file = gr.File(label=\"Download Conversation\")\n",
        "\n",
        "        mic_input.change(\n",
        "            fn=handle_voice_chat,\n",
        "            inputs=[mic_input, conversation_state],\n",
        "            outputs=[conversation_state, ai_audio, chat_output]\n",
        "        )\n",
        "\n",
        "        export_btn.click(\n",
        "            fn=export_conversation,\n",
        "            inputs=[conversation_state],\n",
        "            outputs=[export_file]\n",
        "        )\n",
        "\n",
        "    # Enable mic input after upload\n",
        "    file_input.upload(\n",
        "        fn=handle_file_upload,\n",
        "        inputs=[file_input, file_count_state],\n",
        "        outputs=[\n",
        "            summary_output,\n",
        "            file_input,\n",
        "            file_count_display,\n",
        "            file_count_state,\n",
        "            tts_audio,\n",
        "            mic_input\n",
        "        ]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "TPZb_yaYN2wa",
        "outputId": "6a978ad2-e472-42b8-cc70-9faa6d3f0155"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://372624cb694d3925ee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://372624cb694d3925ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install edge-tts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIFKi6_AO6Wi",
        "outputId": "214a74c0-f4e5-4437-b3d6-d9dec9fe9a2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edge-tts\n",
            "  Downloading edge_tts-7.0.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (3.11.15)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (2025.4.26)\n",
            "Collecting srt<4.0.0,>=3.4.1 (from edge-tts)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate<1.0.0,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from edge-tts) (4.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.0->edge-tts) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge-tts) (3.10)\n",
            "Downloading edge_tts-7.0.2-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22427 sha256=b856ece9aaf3c7ecdada4eb265dcc2c93c0d1c065d5f92476a489ac810415713\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, edge-tts\n",
            "Successfully installed edge-tts-7.0.2 srt-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "# --- Placeholder summarization logic ---\n",
        "def summarize_document(file):\n",
        "    return \"This is a placeholder summary. Replace this with actual summary logic.\"\n",
        "\n",
        "# --- Save TTS output to /content for Colab compatibility ---\n",
        "def summary_text_to_speech(summary_text):\n",
        "    if not summary_text or summary_text.strip() == \"\":\n",
        "        return None\n",
        "    tts = gTTS(text=summary_text, lang='en')\n",
        "    file_path = f\"/content/summary_{uuid.uuid4().hex}.mp3\"\n",
        "    tts.save(file_path)\n",
        "    return file_path\n",
        "\n",
        "def tts_response(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    file_path = f\"/content/ai_response_{uuid.uuid4().hex}.mp3\"\n",
        "    tts.save(file_path)\n",
        "    return file_path\n",
        "\n",
        "# --- File upload handling ---\n",
        "def handle_file_upload(file, file_count):\n",
        "    file_name = os.path.basename(file.name) if hasattr(file, \"name\") else str(file)\n",
        "    print(\"Uploaded file name:\", file_name)\n",
        "    summary = summarize_document(file)\n",
        "    file_count += 1\n",
        "    summary_audio = summary_text_to_speech(summary)\n",
        "    return (\n",
        "        summary,\n",
        "        gr.update(value=None, interactive=True),\n",
        "        f\"Files uploaded this session: {file_count}\",\n",
        "        file_count,\n",
        "        summary_audio,\n",
        "        gr.update(interactive=True)  # Enable mic input\n",
        "    )\n",
        "\n",
        "# --- Voice chat processing ---\n",
        "def transcribe_audio(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            user_text = recognizer.recognize_google(audio_data, language=\"en-US\")\n",
        "            return user_text\n",
        "        except sr.UnknownValueError:\n",
        "            return \"[Unrecognized speech]\"\n",
        "        except sr.RequestError:\n",
        "            return \"[Speech recognition service unavailable]\"\n",
        "\n",
        "def process_voice_input(transcribed_text):\n",
        "    return f\"{transcribed_text}\"\n",
        "\n",
        "def handle_voice_chat(audio_file, chat_history):\n",
        "    if audio_file is None:\n",
        "        return chat_history, None, \"\\n\\n\".join(chat_history) if chat_history else \"\"\n",
        "    user_text = transcribe_audio(audio_file)\n",
        "    chat_history = chat_history or []\n",
        "    chat_history.append(f\"You: {user_text}\")\n",
        "    ai_text = process_voice_input(user_text)\n",
        "    chat_history.append(f\"AI: {ai_text}\")\n",
        "    ai_audio = tts_response(ai_text)\n",
        "    conversation_display = \"\\n\\n\".join(chat_history)\n",
        "    return chat_history, ai_audio, conversation_display\n",
        "\n",
        "# --- Export conversation to downloadable file ---\n",
        "def export_conversation(chat_history):\n",
        "    if not chat_history:\n",
        "        return None\n",
        "    conversation_text = \"\\n\\n\".join(chat_history)\n",
        "    file_path = f\"/content/conversation_{uuid.uuid4().hex}.txt\"\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(conversation_text)\n",
        "    return file_path\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # 📄 Voice Reports\n",
        "        **Upload a document to get a summary and enable voice chat!**\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # File Upload & Summary\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 📤 Document Upload & Summary\")\n",
        "        file_count_state = gr.State(0)\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Upload Document\", interactive=True)\n",
        "            summary_output = gr.Textbox(label=\"Summary\", lines=10, interactive=False, show_copy_button=True)\n",
        "        file_count_display = gr.Markdown(\"Files uploaded this session: 0\")\n",
        "        gr.Markdown(\"**Tip:** Uploading a new file will automatically replace the previous one.\")\n",
        "        with gr.Row():\n",
        "            tts_audio = gr.Audio(label=\"Summary Audio\", interactive=False, autoplay=True)\n",
        "\n",
        "        file_input.upload(\n",
        "            fn=handle_file_upload,\n",
        "            inputs=[file_input, file_count_state],\n",
        "            outputs=[\n",
        "                summary_output,\n",
        "                file_input,\n",
        "                file_count_display,\n",
        "                file_count_state,\n",
        "                tts_audio,\n",
        "                # mic_input enabled later\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # Voice Chat\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"## 🎤 Voice Chat\")\n",
        "        conversation_state = gr.State([])\n",
        "        with gr.Row():\n",
        "            mic_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak Now\", interactive=False)\n",
        "            ai_audio = gr.Audio(label=\"AI Speaking\", interactive=False, autoplay=True)\n",
        "        chat_output = gr.Textbox(label=\"Conversation\", lines=12, interactive=False, show_copy_button=True)\n",
        "        with gr.Row():\n",
        "            export_btn = gr.Button(\"Export Conversation\")\n",
        "            export_file = gr.File(label=\"Download Conversation\")\n",
        "\n",
        "        mic_input.change(\n",
        "            fn=handle_voice_chat,\n",
        "            inputs=[mic_input, conversation_state],\n",
        "            outputs=[conversation_state, ai_audio, chat_output]\n",
        "        )\n",
        "\n",
        "        export_btn.click(\n",
        "            fn=export_conversation,\n",
        "            inputs=[conversation_state],\n",
        "            outputs=[export_file]\n",
        "        )\n",
        "\n",
        "    # Enable mic after file upload\n",
        "    file_input.upload(\n",
        "        fn=handle_file_upload,\n",
        "        inputs=[file_input, file_count_state],\n",
        "        outputs=[\n",
        "            summary_output,\n",
        "            file_input,\n",
        "            file_count_display,\n",
        "            file_count_state,\n",
        "            tts_audio,\n",
        "            mic_input\n",
        "        ]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "zZo4hmtMPR9q",
        "outputId": "e126d959-e918-4618-8b08-c5e4fa7ce005"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://92367b52eb263532e6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://92367b52eb263532e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b5DfEcK4Bqg3"
      }
    }
  ]
}